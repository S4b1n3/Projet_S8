{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "includes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./clusterdata-2011-2/task_events/part-00000-of-00500.csv.gz\n",
      "to\n",
      "./clusterdata-2011-2/task_events/part-00000-of-00500.csv.gz\n"
     ]
    }
   ],
   "source": [
    "tracesPath='./clusterdata-2011-2'\n",
    "tasksNums = range(0,1)\n",
    "\n",
    "tasksFiles=list(map(lambda x:tracesPath+'/task_events/part-'+str(x).zfill(5)+'-of-00500.csv.gz', tasksNums))\n",
    "\n",
    "print (tasksFiles[0])\n",
    "print ('to')\n",
    "print (tasksFiles[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genJobs(taskfiles):\n",
    "    tasks={}\n",
    "    arrival=[]\n",
    "    current_time=0\n",
    "    jobs = []\n",
    "    def task_complete(jID, tID):\n",
    "        (res, prio, evts) = tasks[(jID, tID)]\n",
    "        if len(evts) < 3:\n",
    "            #bad_tasks.append((jID, tID))\n",
    "            pass\n",
    "        else:\n",
    "            subtime=evts[0][1] #timestamp du debut\n",
    "            runtime=evts[1][1] #event du lancement de la tache\n",
    "            endtime=evts[-1][1] #fin de la tache\n",
    "            \n",
    "            #temps en seconde\n",
    "            subt=subtime/1000000.0\n",
    "            #temps d'execution\n",
    "            walltime=float(endtime-runtime)/1000000.0\n",
    "            \n",
    "            job={}\n",
    "            job['id'] = tID\n",
    "            job['profile'] = \"delay_ft.B.1\"\n",
    "            job['res'] = int(res*100)\n",
    "            job['subtime'] = subt\n",
    "            job['walltime'] = walltime\n",
    "            \n",
    "            jobs.append(job)\n",
    "            \n",
    "            #print(json.dumps(job))\n",
    "            \n",
    "            del tasks[(jID, tID)]\n",
    "    \n",
    "    \n",
    "    for f in tasksFiles:\n",
    "        print ('File: ', f)\n",
    "        with gzip.open(f, 'rb') as f:\n",
    "            for line in f.readlines():\n",
    "                \n",
    "                \"\"\"\n",
    "                1. timestamp\n",
    "                2. missing info\n",
    "                3. job ID\n",
    "                4. task index - within the job\n",
    "                5. machine ID\n",
    "                6. event type\n",
    "                7. user name\n",
    "                8. scheduling class\n",
    "                9. priority\n",
    "                10. resource request for CPU cores\n",
    "                11. resource request for RAM\n",
    "                12. resource request for local disk space\n",
    "                13. different-machine constraint\n",
    "                \"\"\"\n",
    "                \n",
    "                (timestamp,_,jID,tID,_,evtType,_,_,prio,res,_,_,_)=line.decode(\"ascii\").split(',')\n",
    "                try:\n",
    "                    # début de la tache\n",
    "                    if(evtType == '0'):\n",
    "                        timestamp=int(timestamp)\n",
    "                        #on récupère la class, la prio, et le temps depuis le début, qu'on stock\n",
    "                        tasks[(int(jID), int(tID))] = (float(res), int(prio), [(0,int(timestamp))])\n",
    "                        #on actualise le temps\n",
    "                        if timestamp>0:\n",
    "                            arrival.append(timestamp-current_time)\n",
    "                            current_time=timestamp\n",
    "                            \n",
    "                    # event de la tache en cours        \n",
    "                    else:\n",
    "                        \n",
    "                        timestamp, jID, tID, evtType = int(timestamp), int(jID), int(tID), int(evtType)\n",
    "                        (_,_, events)=tasks[(jID,tID)]\n",
    "                        #on rajoute le timestamp de l'evenement\n",
    "                        events.append((evtType,timestamp))\n",
    "                        \n",
    "                        #fin de la tache\n",
    "                        if evtType == 4 or evtType == 5:\n",
    "                            task_complete(jID, tID)\n",
    "                            \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  ./clusterdata-2011-2/task_events/part-00000-of-00500.csv.gz\n"
     ]
    }
   ],
   "source": [
    "jsonPath = \"./workload.json\"\n",
    "\n",
    "outputData = {}\n",
    "outputData['description'] =\"Workload from google data\"\n",
    "outputData['date'] = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "outputData['jobs'] = genJobs(tasksFiles)\n",
    "\n",
    "with open(jsonPath, \"w\") as jsonF:\n",
    "    jsonF.write(json.dumps(outputData, indent = 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
