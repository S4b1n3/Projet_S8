{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "includes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./clusterdata-2011-2/task_events/part-00000-of-00500.csv.gz\n",
      "to\n",
      "./clusterdata-2011-2/task_events/part-00019-of-00500.csv.gz\n"
     ]
    }
   ],
   "source": [
    "tracesPath='./clusterdata-2011-2'\n",
    "tasksNums = range(0,20)\n",
    "\n",
    "tasksFiles=list(map(lambda x:tracesPath+'/task_events/part-'+str(x).zfill(5)+'-of-00500.csv.gz', tasksNums))\n",
    "\n",
    "print (tasksFiles[0])\n",
    "print ('to')\n",
    "print (tasksFiles[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genJobs(taskfiles):\n",
    "    tasks={}\n",
    "    arrival=[]\n",
    "    current_time=0\n",
    "    jobs = []\n",
    "    profiles = {}\n",
    "    \n",
    "    def task_complete(jID, tID):\n",
    "        (res, prio, evts) = tasks[(jID, tID)]\n",
    "        if len(evts) < 3:\n",
    "            #bad_tasks.append((jID, tID))\n",
    "            pass\n",
    "        else:\n",
    "            subtime=evts[0][1] #timestamp du debut\n",
    "            runtime=evts[1][1] #event du lancement de la tache\n",
    "            endtime=evts[-1][1] #fin de la tache\n",
    "            \n",
    "            if evts[-1][0]==4 and res!=0.0:        \n",
    "                #temps en seconde\n",
    "                subt=subtime/1000000.0\n",
    "                #temps maximun\n",
    "                walltime=float(endtime-runtime)/1000000.0\n",
    "\n",
    "                #creation du job\n",
    "                job={}\n",
    "                job['id'] = str(jID) + \"-\" + str(tID) + \"-\" + str(subt)\n",
    "                job['profile'] = str(floor(walltime))\n",
    "                job['res'] = int(res*21000)\n",
    "                if int(res*21000)==0:\n",
    "                    job['res'] = 1 \n",
    "                job['subtime'] = floor(subt)\n",
    "                job['walltime'] = floor(walltime*2)\n",
    "\n",
    "                jobs.append(job)\n",
    "                \n",
    "                #creation d'un profile avec le temps de la task\n",
    "                profiles[str(floor(walltime))]={}\n",
    "                profiles[str(floor(walltime))]['type']=\"delay\"\n",
    "                profiles[str(floor(walltime))]['delay']=floor(walltime)\n",
    "\n",
    "                #print(json.dumps(profiles))\n",
    "                #print(json.dumps(job))\n",
    "\n",
    "                del tasks[(jID, tID)]\n",
    "    \n",
    "    for f in tasksFiles:\n",
    "        print('File: ', f)\n",
    "        with gzip.open(f, 'rb') as f:\n",
    "            for line in f.readlines():\n",
    "                \n",
    "                \"\"\"\n",
    "                1. timestamp\n",
    "                2. missing info\n",
    "                3. job ID\n",
    "                4. task index - within the job\n",
    "                5. machine ID\n",
    "                6. event type\n",
    "                7. user name\n",
    "                8. scheduling class\n",
    "                9. priority\n",
    "                10. resource request for CPU cores\n",
    "                11. resource request for RAM\n",
    "                12. resource request for local disk space\n",
    "                13. different-machine constraint\n",
    "                \"\"\"\n",
    "                \n",
    "                (timestamp,_,jID,tID,_,evtType,_,_,prio,res,_,_,_)=line.decode(\"ascii\").split(',')\n",
    "                try:\n",
    "                    # début de la tache\n",
    "                    if(evtType == '0'):\n",
    "                        timestamp=int(timestamp)\n",
    "                        #on récupère la class, la prio, et le temps depuis le début, qu'on stock\n",
    "                        tasks[(int(jID), int(tID))] = (float(res), int(prio), [(0,int(timestamp))])\n",
    "                        #on actualise le temps\n",
    "                        if timestamp>0:\n",
    "                            arrival.append(timestamp-current_time)\n",
    "                            current_time=timestamp\n",
    "                            \n",
    "                    # event de la tache en cours        \n",
    "                    else:\n",
    "                        \n",
    "                        timestamp, jID, tID, evtType = int(timestamp), int(jID), int(tID), int(evtType)\n",
    "                        (_,_, events)=tasks[(jID,tID)]\n",
    "                        #on rajoute le timestamp de l'evenement\n",
    "                        events.append((evtType,timestamp))\n",
    "                        \n",
    "                        #fin de la tache\n",
    "                        if evtType == 4 or evtType == 5:\n",
    "                            task_complete(jID, tID)\n",
    "                            \n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "                \n",
    "    return (jobs,profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  ./clusterdata-2011-2/task_events/part-00000-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00001-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00002-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00003-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00004-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00005-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00006-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00007-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00008-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00009-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00010-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00011-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00012-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00013-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00014-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00015-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00016-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00017-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00018-of-00500.csv.gz\n",
      "File:  ./clusterdata-2011-2/task_events/part-00019-of-00500.csv.gz\n"
     ]
    }
   ],
   "source": [
    "jsonPath = \"./workload.json\"\n",
    "\n",
    "outputData = {}\n",
    "outputData['description'] =\"Workload from google data\"\n",
    "outputData['date'] = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "outputData['nb_res'] = 21000\n",
    "\n",
    "(j,p)= genJobs(tasksFiles)\n",
    "\n",
    "outputData['profiles'] = p\n",
    "        \n",
    "\n",
    "outputData['jobs'] = j[0:len(j):500]\n",
    "\n",
    "with open(jsonPath, \"w\") as jsonF:\n",
    "    jsonF.write(json.dumps(outputData, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
